{"cells":[{"cell_type":"markdown","metadata":{"id":"xn28qgmjmpwU"},"source":["# Bllossom-8B를 이용한 한국어 LLM 튜토리얼\n","\n","> [유튜브 빵형의 개발도상국](https://www.youtube.com/@bbanghyong)\n","\n","https://huggingface.co/MLP-KTLim/llama3-Bllossom"]},{"cell_type":"markdown","metadata":{"id":"TwtKm4_Wmud6"},"source":["## 01. 활용할 package 설정\n"," - GPU사용하기: colab에서 런타임 --> 런타임유형변경 --> T4 선택\n"," - 패키지설치: 아래 pip를 이용해 Transformers, accelerate 설치\n"," - 런타임재시작: 런타임 --> 세션다시시작  (accelerate설치 시 런타임 다시시작하셔야됩니다!)"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":7078,"status":"ok","timestamp":1729053555379,"user":{"displayName":"김상욱","userId":"12120376734160382512"},"user_tz":-540},"id":"i5xmsZ2fOdAk"},"outputs":[],"source":["!pip install -q transformers==4.40.0 accelerate gradio"]},{"cell_type":"code","source":["!pip install torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H8TTiKgIkyDu","executionInfo":{"status":"ok","timestamp":1729053561346,"user_tz":-540,"elapsed":5970,"user":{"displayName":"김상욱","userId":"12120376734160382512"}},"outputId":"ce0135f1-6298-4f51-91b9-e8aa496dd492"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"irNZYVFGnZEs"},"source":["## 02. 모델준비"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"executionInfo":{"elapsed":4,"status":"error","timestamp":1729053755245,"user":{"displayName":"김상욱","userId":"12120376734160382512"},"user_tz":-540},"id":"rmF8wfz3NhZt","outputId":"8d217698-af5d-47fe-d7b2-521f50d4a1bc"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name '_C' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-37aa2b276847>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'MLP-KTLim/llama3-Bllossom'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0m__name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m__name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m__name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m__name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0m__all__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"]}],"source":["import os\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","model_id = 'MLP-KTLim/llama3-Bllossom'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    torch_dtype=torch.bfloat16,\n","    device_map=\"auto\",\n",")\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148},"executionInfo":{"elapsed":404,"status":"error","timestamp":1729052528388,"user":{"displayName":"김상욱","userId":"12120376734160382512"},"user_tz":-540},"id":"j4bz0nAFD-1T","outputId":"75a5bb7a-c241-4637-e000-1c13183e3022"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'tokenizer' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-3009d7b87c16>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"]}],"source":["tokenizer.eos_token_id"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1729045552536,"user":{"displayName":"김상욱","userId":"12120376734160382512"},"user_tz":-540},"id":"PVPKSJi8EFn0","outputId":"c2fa6a22-00f0-4707-ea52-d794a569b123"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'MLP-KTLim/llama3-Bllossom'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["model_id"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1729045552536,"user":{"displayName":"김상욱","userId":"12120376734160382512"},"user_tz":-540},"id":"T5JlNJhgEORr","outputId":"c3064cab-ddf9-44a8-b0be-2b27ff7d5c15"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LlamaForCausalLM(\n","  (model): LlamaModel(\n","    (embed_tokens): Embedding(128256, 4096)\n","    (layers): ModuleList(\n","      (0-31): 32 x LlamaDecoderLayer(\n","        (self_attn): LlamaSdpaAttention(\n","          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n","          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n","          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n","          (rotary_emb): LlamaRotaryEmbedding()\n","        )\n","        (mlp): LlamaMLP(\n","          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n","          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n","          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): LlamaRMSNorm()\n","        (post_attention_layernorm): LlamaRMSNorm()\n","      )\n","    )\n","    (norm): LlamaRMSNorm()\n","  )\n","  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",")"]},"metadata":{},"execution_count":5}],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1729045552537,"user":{"displayName":"김상욱","userId":"12120376734160382512"},"user_tz":-540},"id":"aS7gMPDzEFa2","outputId":"bb6d7434-5fe3-4c42-9f21-ecf69fe7a5d0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LlamaConfig {\n","  \"_name_or_path\": \"MLP-KTLim/llama3-Bllossom\",\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": 128009,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 4096,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 14336,\n","  \"max_position_embeddings\": 8192,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 8,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.40.0\",\n","  \"use_cache\": false,\n","  \"vocab_size\": 128256\n","}"]},"metadata":{},"execution_count":6}],"source":["model.config"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34208,"status":"ok","timestamp":1729045586716,"user":{"displayName":"김상욱","userId":"12120376734160382512"},"user_tz":-540},"id":"DEhod3BKW6wF","outputId":"9c5e6ec5-f6c3-4ae3-a86e-d2464e01c80d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"bHcxdlTTnhqs"},"source":["## 03. 추론"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"zlSSOAUuOUmh","outputId":"bb7902f0-6bf1-4afc-bbe1-cad867b28f1a"},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["논문 요약:\n","\n","논문 \"Optimizing Language Augmentation for Multilingual Large Language Models: A Case Study on Korean\"에서는 다중 언어 대규모 언어 모델(Large Language Models, LLMs)의 성능을 향상시키기 위해 언어 증강(language augmentation)을 최적화하는 방법을 탐구합니다. 특히 이 연구는 한국어를 대상으로 한 사례 연구를 통해 이러한 문제를 해결하기 위한 접근법을 제안합니다.\n","\n","### 주요 내용\n","\n","1. **언어 증강의 중요성**: 자연어 처리(NLP) 작업에서 언어 모델의 학습 데이터 양과 품질이 매우 중요합니다. 그러나 특정 언어에 대한 데이터가 부족하거나 불균형일 경우, 모델의 일반화 능력과 성능이 저하될 수 있습니다. 이를 해결하기 위해 언어 증강 기법이 사용됩니다.\n","\n","2. **현재 상태와 한계**: 기존의 언어 증강 기법들은 주로 단어-level 또는 문장-level에서 이루어지며, 다중 언어 환경에서의 적용에는 한계가 있습니다. 또한, 각 언어의 문법적 구조와 문화적 특성이 고려되지 않아 성능 차이를 초래할 수 있습니다\n"]}],"source":["PROMPT = '''당신은 유용한 AI 어시스턴트입니다. 사용자의 질의에 대해 친절하고 정확하게 답변해야 합니다.'''\n","instruction = \"다음 제목의 논문을 요약해줘 'Optimizing Language Augmentation for Multilingual Large Language Models: A Case Study on Korean'\"\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n","    {\"role\": \"user\", \"content\": f\"{instruction}\"}\n","]\n","\n","input_ids = tokenizer.apply_chat_template(\n","    messages,\n","    add_generation_prompt=True,\n","    return_tensors=\"pt\"\n",").to(model.device)\n","\n","terminators = [\n","    tokenizer.eos_token_id,\n","    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n","]\n","\n","outputs = model.generate(\n","    input_ids,\n","    max_new_tokens=256,\n","    eos_token_id=terminators,\n","    do_sample=True,\n","    temperature=0.6,\n","    top_p=0.9,\n","    repetition_penalty=1.1\n",")\n","\n","print(tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161,"referenced_widgets":["33fe287fcfa84176b79a5dd02775b4b9","a352b7ca9beb45df8d097b4d8bc1f860","63d6048a5e1146629652ac4c23e756de","026cbcf406da4968a498f6436d8bb775","9e059d832199453887afcc31d6208035","8f00bc23f42345cea2c2cef54c942caa","443c6506c81d461883f7f45adec345fc","745f8282d19c407b8360a0099ba32710","fb70f9ff2d9a4aa9860717a270b61f0b","ad24d5e8318b4bf6956caa6096718f31","f6b9c672f38a4e0eaabeffced7d70d38"]},"executionInfo":{"elapsed":4014318,"status":"ok","timestamp":1728970242515,"user":{"displayName":"김상욱","userId":"12120376734160382512"},"user_tz":-540},"id":"W-PGwMm9arCu","outputId":"c469196d-08b5-4726-f0e8-f0fc19067970"},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33fe287fcfa84176b79a5dd02775b4b9","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["생성된 텍스트: 한국의 인공지능 발전을 위해 필요한 요소는 무엇일까요? 먼저, 정부와 민간 기업이 함께 협력하여 인공지능 연구개발에 대한 투자와 지원이 필요합니다. 또한, 데이터의 수집과 분석이 중요한데, 이를 위해서는 개인정보 보호와 관련된 법적 구조가 마련되어야 합니다. 그리고 교육과 훈련도 중요합니다. 인공지능 기술이 다양하게 적용되기 위해서는 기존\n"]}],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","# 모델과 토크나이저 로드\n","model_id = 'MLP-KTLim/llama3-Bllossom'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    torch_dtype=torch.bfloat16,  # bfloat16을 사용하여 메모리 최적화\n","    device_map=\"auto\"            # GPU 사용이 가능할 경우 자동 할당\n",")\n","model.eval()  # 모델을 평가 모드로 설정\n","\n","def generate_text(prompt, max_length=100, temperature=0.7, top_p=0.9):\n","    # 입력 프롬프트를 토크나이징\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n","\n","    # 모델을 통해 문장 생성\n","    with torch.no_grad():  # 평가 모드에서는 그래디언트 계산 비활성화\n","        outputs = model.generate(\n","            input_ids,\n","            max_length=max_length,   # 생성할 최대 문장의 길이\n","            do_sample=True,          # 샘플링 방식 사용\n","            temperature=temperature, # 생성의 무작위성 조절\n","            top_p=top_p,             # Top-p 샘플링을 통해 확률 상위 토큰들 중 선택\n","            repetition_penalty=1.1,  # 반복 방지\n","            eos_token_id=tokenizer.eos_token_id  # 문장이 끝나는 지점을 정의\n","        )\n","\n","    # 생성된 토큰을 텍스트로 디코딩\n","    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return generated_text\n","\n","# 예시 프롬프트로 문장 생성\n","prompt = \"한국의 인공지능 발전을 위해 필요한 요소는\"\n","generated_output = generate_text(prompt)\n","\n","# 생성된 텍스트 출력\n","print(\"생성된 텍스트:\", generated_output)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"aYgViYJzBU0h","outputId":"cc5e56e1-93c3-4b5e-ed3a-f56f28f44268"},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["### 원관념: 전문성\n","\n","**보조관념 1: 지식**\n","- **비유문장:** \"전문성이란 하나의 큰 책방에서 수많은 책을 잘 알고 있는 도서관 관리자와 같다. 다양한 분야의 지식을 소화하고, 언제든지 필요한 정보를 빠르게 찾아내어 문제를 해결할 수 있어야 한다.\"\n","- **이유:** 지식은 전문성을 구성하는 중요한 요소로, 특정 분야에서 깊이 있고 넓게 이해된 정보는 전문가로서의 신뢰성을 높인다.\n","\n","**보조관념 2: 실무 경험**\n","- **비유문장:** \"전문성이란 강한 물건을 다루는 기술을 가진 조각사와 같다. 시간이 지나면서 점점 더 정교하고 복잡한 작품을 만들어낼 수 있게 되어야 한다.\"\n","- **이유:** 실제로 많은 상황에서 적용해보며 쌓은 실무 경험은 전문성을 더욱 풍부하게 하고, 예상치 못한 상황에서도 효과적으로 대처할 수 있는 능력을 키준다.\n","\n","**보조관념 3: 분석 및 문제 해결 능력**\n","- **\n"]}],"source":["PROMPT = '''당신은 유용한 AI 어시스턴트입니다. 제시해주는 원관념(핵심역량)을 통해서 새로운 보조관념과 그에 따른 비유문장 생성해야돼 '''\n","instruction = \"'나의 핵심역량(원관념)은 전문성이고 보조관념(비행기 기장)이랑 비유문장 그리고 이유도 설명해봐 '\"\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": f\"{PROMPT}\"},\n","    {\"role\": \"user\", \"content\": f\"{instruction}\"}\n","]\n","\n","input_ids = tokenizer.apply_chat_template(\n","    messages,\n","    add_generation_prompt=True,\n","    return_tensors=\"pt\"\n",").to(model.device)\n","\n","terminators = [\n","    tokenizer.eos_token_id,\n","    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n","]\n","\n","outputs = model.generate(\n","    input_ids,\n","    max_new_tokens=256,\n","    eos_token_id=terminators,\n","    do_sample=True,\n","    temperature=0.6,\n","    top_p=0.9,\n","    repetition_penalty=1.1\n",")\n","\n","print(tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True))"]},{"cell_type":"code","source":["import torch\n","\n","torch.cuda.empty_cache()\n","#gpu 안쓰는 메모리 정리?하는 코드"],"metadata":{"id":"MDPkafLIKLnw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QO3VuzYnBUvM","colab":{"base_uri":"https://localhost:8080/","height":474,"referenced_widgets":["31e5a2377d5543a0a449448c5c4f3387","a92f1baeca964a409d277a05e721de1b","0fa2e51f6213420d94369c8cf6714fd6","16f777e36242490ab15b057c1f8abd70","d67238c3ccf443048a42ebcc704c45a1","6dafe270c2864aac8d4245cca0cdf74b","cf182a21bb364ee6b0e822dc10d81ee3","afa9852527ff426fa3599bb6f1f376f1","534911b654924a2bbd388935b535c12b","2716bc4e29c649388c943e00d124234e","cea1cecf03564c2abe581e019c01129e"]},"executionInfo":{"status":"ok","timestamp":1729045895476,"user_tz":-540,"elapsed":117606,"user":{"displayName":"김상욱","userId":"12120376734160382512"}},"outputId":"5debc42c-82cb-4725-84db-93d238af387f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:1462: UserWarning: Current model requires 134221824 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31e5a2377d5543a0a449448c5c4f3387"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["생성된 텍스트: 당신은 유용한 AI 어시스턴트입니다. 제시해주는 원관념(핵심역량)을 통해서 새로운 보조관념과 그에 따른 비유문장 생성해야돼 \n","나의 핵심역량(원관념)은 전문성이고 보조관념(비행기 기장)이랑 비유문장 그리고 이유도 설명해봐 \n","\n","\n","\n","\n","\n","---\n","\n","**원관념: 전문성**\n","**보조관념: 비행기 기장**\n","**비유문장:** \"전문성이란 비행기를 안전하게 지휘하는 기장을 닮아, 복잡한 상황에서도 정확하고 효율적으로 문제를 해결할 수 있는 능력을 의미한다.\"\n","\n","**이유:**\n","비행기 기장은 안전한 착륙을 위해 다양한 요소를 고려하여 조종을 해야 한다. 마찬가지로 전문가는 자신의 분야에서 최신 정보와 경험을 바탕으로 문제를 해결하며, 이를 통해 더 나은 결과를 도출한다. 또한, 비행기 기장은 항상 주의를 기울여야 하며, 실수를 용납하지 않는 철학을 가지고 있다. 전문가도 자신의 업무를 철\n"]}],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","# 모델과 토크나이저 로드\n","model_id = 'MLP-KTLim/llama3-Bllossom'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    torch_dtype=torch.bfloat16,  # bfloat16을 사용하여 메모리 최적화\n","    device_map=\"auto\"            # GPU 사용이 가능할 경우 자동 할당\n",")\n","model.eval()  # 모델을 평가 모드로 설정\n","\n","# 시스템 프롬프트와 사용자의 요청을 병합한 프롬프트\n","PROMPT = '''당신은 유용한 AI 어시스턴트입니다. 제시해주는 원관념(핵심역량)을 통해서 새로운 보조관념과 그에 따른 비유문장 생성해야돼 '''\n","instruction = \"나의 핵심역량(원관념)은 전문성이고 보조관념(비행기 기장)이랑 비유문장 그리고 이유도 설명해봐 \"\n","\n","# 프롬프트 병합\n","full_prompt = f\"{PROMPT}\\n{instruction}\"\n","\n","def generate_text(prompt, max_length=256, temperature=0.7, top_p=0.9):\n","    # 입력 프롬프트를 토크나이징\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n","\n","    # 모델을 통해 문장 생성\n","    with torch.no_grad():  # 평가 모드에서는 그래디언트 계산 비활성화\n","        outputs = model.generate(\n","            input_ids,\n","            max_length=max_length,   # 생성할 최대 문장의 길이\n","            do_sample=True,          # 샘플링 방식 사용\n","            temperature=temperature, # 생성의 무작위성 조절\n","            top_p=top_p,             # Top-p 샘플링을 통해 확률 상위 토큰들 중 선택\n","            repetition_penalty=1.1,  # 반복 방지\n","            eos_token_id=tokenizer.eos_token_id  # 문장이 끝나는 지점을 정의\n","        )\n","\n","    # 생성된 토큰을 텍스트로 디코딩\n","    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return generated_text\n","\n","# 병합된 프롬프트로 문장 생성\n","generated_output = generate_text(full_prompt)\n","\n","# 생성된 텍스트 출력\n","print(\"생성된 텍스트:\", generated_output)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"BupQDfliRadU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLCWb80WBUom","colab":{"base_uri":"https://localhost:8080/","height":437,"referenced_widgets":["0c2e5e94388846c0a5dcc1266f6a485c","53b3b413013d4e91b67356eb97649e85","a8226eb399424e6787e93f8dc7b8e255","a3d6f5e6f19647e59e5258dc99b51d98","8063d16d70b447a5bce20c647b11f744","1320bbf4642b44f6b4c834ba23efc4df","443e2640b60b4f88be2377faa50e2a70","3536af6225e3456c9965d4abebcc6dd4","2a8a132a63b1459fac1478a9a2e901de","d909668954344ba0a6bb6ed12a66304a","e9e317bde20f48a7982aa92ecedc588a"]},"executionInfo":{"status":"ok","timestamp":1729048073246,"user_tz":-540,"elapsed":317702,"user":{"displayName":"김상욱","userId":"12120376734160382512"}},"outputId":"74288a9d-8aad-4cff-dc82-ab66e3bac605"},"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c2e5e94388846c0a5dcc1266f6a485c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["생성된 텍스트: 당신은 유용한 AI 어시스턴트입니다. 제시해주는 원관념(핵심역량)을 통해서 새로운 보조관념과 그에 따른 비유문장 생성해야돼 \n","나의 핵심역량(원관념)은 전문성, 협응력, 주도성이고 각각에 맞는 보조관념이랑 비유문장 그리고 이유도 설명해봐 1차원적인 답변보다는 다양한 측면에서 접근해보세요. \n","\n","**전문성**\n","- **보조관념**: 지식, 기술\n","- **비유문장**: \"어떤 사람처럼 전문성을 가지는 것은 강력한 무기가 되며, 이를 통해 문제를 해결하고 목표를 달성하는 능력을 갖춘다.\"\n","- **이유**: 전문성은 특정 분야에서 깊이 있는 지식과 기술을 의미한다. 이는 전문가로서의 역할을 수행하는데 필수적이며, 다른 사람들이 어려워하는 문제를 해결하고, 새로운 아이디어와 솔루션을 제시할 수 있게 해준다.\n","\n","**협응력**\n","- **보조관념**: 소통, 공감\n","- **비유문장**: \"협응력은 서로 다른 언어로 말하더라도 이해할 수 있는 특별한 통역사역이다. 이는 팀워크와 조화를 이루는 중요한 요소로, 서로를 존중하고 지원하며 성공적인 결과를 도모하는 데 기여한다.\"\n","- **이유**: 협응력은 다른 사람들과 효과적으로 소통하고, 그들의 의견을 이해하고 공감하는 능력을 의미한다. 이는 팀워크를 강화하고, 갈등을 줄이고, 더 나은 결정을 내리는 데 중요하다. 또한, 다양한 관점을 고려하여 더 창의적이고 혁신적인 접근 방식을 모색할 수 있게 한다.\n","\n","**주도성**\n","- **보조관념**: 리더십,_INITIATIVE_\n","- **비유문장**: \"주도성이 있는 사람은 불확실한 상황에서도 선두에 서서 길을 열고, 동료들을 이끌어 항상 새로운 도전에 나선다. 이는 팀 전체가 성장하고 발전할 수 있도록 하는 강력한 동력이 된다.\"\n","- **이유**: 주도성은 자신의 아이디어를 추진하고, 새로운 도전을\n"]}],"source":["# 모델과 토크나이저 로드\n","model_id = 'MLP-KTLim/llama3-Bllossom'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    torch_dtype=torch.bfloat16,  # bfloat16을 사용하여 메모리 최적화\n","    device_map=\"auto\"            # GPU 사용이 가능할 경우 자동 할당\n",")\n","model.eval()  # 모델을 평가 모드로 설정\n","\n","# 시스템 프롬프트와 사용자의 요청을 병합한 프롬프트\n","PROMPT1 = '''당신은 유용한 AI 어시스턴트입니다. 제시해주는 원관념(핵심역량)을 통해서 새로운 보조관념과 그에 따른 비유문장 생성해야돼 '''\n","instruction1 = \"나의 핵심역량(원관념)은 전문성, 협응력, 주도성이고 각각에 맞는 보조관념이랑 비유문장 그리고 이유도 설명해봐 \"\n","\n","full_prompt = f\"{PROMPT1}\\n{instruction1}\"\n","\n","def generate_text(prompt, max_length=512, temperature=0.7, top_p=0.9):\n","    # 입력 프롬프트를 토크나이징\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n","\n","    # 모델을 통해 문장 생성\n","    with torch.no_grad():  # 평가 모드에서는 그래디언트 계산 비활성화\n","        outputs = model.generate(\n","            input_ids,\n","            max_length=max_length,   # 생성할 최대 문장의 길이\n","            do_sample=True,          # 샘플링 방식 사용\n","            temperature=temperature, # 생성의 무작위성 조절\n","            top_p=top_p,             # Top-p 샘플링을 통해 확률 상위 토큰들 중 선택\n","            repetition_penalty=1.1,  # 반복 방지\n","            eos_token_id=tokenizer.eos_token_id  # 문장이 끝나는 지점을 정의\n","        )\n","\n","    # 생성된 토큰을 텍스트로 디코딩\n","    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return generated_text\n","\n","# 병합된 프롬프트로 문장 생성\n","generated_output = generate_text(full_prompt)\n","\n","# 생성된 텍스트 출력\n","print(\"생성된 텍스트:\", generated_output)\n"]},{"cell_type":"code","source":["#prompt 수정 (창의성 추가)"],"metadata":{"id":"Qu4qWg31TQFZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6UlpPEIBUlu","colab":{"base_uri":"https://localhost:8080/","height":548,"referenced_widgets":["4553489c08bd4c5987a163b4d8349cb2","41ccc332cc40440db10135d2da17239e","aa17805ee5894c6a91147642176c557a","895ab69958904d27875a09011fe516f9","55d6e42946fe461bbcbfb0e129a44c88","244687fac58f4c34916918c711965bea","64e41bc660c3402b946015c3f7d0b912","17ce0c0cc03a4959ae6a7df78e4918b0","dae0c51ba2da4824bf35d5580155e6c1","19118d56739948049bc5ef930888eea2","1c72156d8d3545dd99a4ca648ac6b557"]},"executionInfo":{"status":"ok","timestamp":1729048503682,"user_tz":-540,"elapsed":316400,"user":{"displayName":"김상욱","userId":"12120376734160382512"}},"outputId":"3d6b9f13-7733-48cd-dcd5-c3dfa07bd38f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:1462: UserWarning: Current model requires 134221824 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4553489c08bd4c5987a163b4d8349cb2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["생성된 텍스트: 당신은 유용한 AI 어시스턴트입니다. 제시해주는 원관념(핵심역량)을 통해서 새로운 보조관념과 그에 따른 비유문장 생성해야돼 \n","나의 핵심역량(원관념)은 전문성, 협응력, 주도성이고 각각에 맞는 보조관념이랑 비유문장 그리고 이유도 설명해봐  요약하면 다음과 같습니다.\n","\n","1. **전문성**\n","   - 보조관념: 깊이 있는 지식\n","   - 비유문장: \"그의 전문성이 빛나는 별처럼 다른 사람들에게 희망을 주는 길이 되듯이, 우리 팀에서도 그의 역할이 매우 중요합니다.\"\n","   - 이유: 전문성을 가진 사람이 팀 내에서 리더로서 중요한 역할을 할 수 있으며, 그들의 지식과 경험은 팀의 성장을 돕습니다. 비유문장은 이러한 전문성을 강조하고, 팀에서의 중요성을 시각적으로 표현합니다.\n","\n","2. **협응력**\n","   - 보조관념: 조화로운 상호작용\n","   - 비유문장: \"팀워크를 위한 유명한 멜로디가 들려오는 것처럼, 모두가 서로의 장점을 존중하며 조화를 이루는 모습이 참으로 아름답습니다.\"\n","   - 이유: 협응력이 높은 팀은 서로의 강점을 최대한 활용할 수 있으며, 이를 통해 더 나은 결과를 얻을 수 있습니다. 비유문장은 협업의 중요성을 강조하고, 조화로운 상호작용을 시각적으로 표현합니다.\n","\n","3. **주도성**\n","   - 보조관념: 목표 달성\n","   - 비유문장: \"목표를 향해 가는 열차처럼, 그가 앞서 나서는 것은 우리 모두에게 도움이 됩니다. 함께 끌어올리는 열차로, 더욱 큰 성공을 향해 달리겠습니다.\"\n","   - 이유: 주도성이 있는 사람은 목표를 설정하고 이를 달성하기 위해 노력하는 역할을 합니다. 비유문장은 이러한 주도성을 강조하고, 목표 달성을 위한 팀의 협력을 시각적으로 표현합니다.\n","\n","이러한 원관념과 보조관념, 비유문장을 통해 당신은 더 나은 방식으로 내가 제공하는 정보를 이해하고, 이를 바탕\n"]}],"source":["# 모델과 토크나이저 로드\n","model_id = 'MLP-KTLim/llama3-Bllossom'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    torch_dtype=torch.bfloat16,  # bfloat16을 사용하여 메모리 최적화\n","    device_map=\"auto\"            # GPU 사용이 가능할 경우 자동 할당\n",")\n","model.eval()  # 모델을 평가 모드로 설정\n","\n","# 시스템 프롬프트와 사용자의 요청을 병합한 프롬프트\n","PROMPT2 = '''당신은 유용한 AI 어시스턴트입니다. 제시해주는 원관념(핵심역량)을 통해서 새로운 '창의성을 가진' 보조관념과 그에 따른 비유문장 생성해야돼 '''\n","instruction1 = \"나의 핵심역량(원관념)은 전문성, 협응력, 주도성이고 각각에 맞는 보조관념이랑 비유문장 그리고 이유도 설명해봐 \"\n","\n","full_prompt = f\"{PROMPT1}\\n{instruction1}\"\n","\n","def generate_text(prompt, max_length=512, temperature=0.7, top_p=0.9):\n","    # 입력 프롬프트를 토크나이징\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n","\n","    # 모델을 통해 문장 생성\n","    with torch.no_grad():  # 평가 모드에서는 그래디언트 계산 비활성화\n","        outputs = model.generate(\n","            input_ids,\n","            max_length=max_length,   # 생성할 최대 문장의 길이\n","            do_sample=True,          # 샘플링 방식 사용\n","            temperature=temperature, # 생성의 무작위성 조절\n","            top_p=top_p,             # Top-p 샘플링을 통해 확률 상위 토큰들 중 선택\n","            repetition_penalty=1.1,  # 반복 방지\n","            eos_token_id=tokenizer.eos_token_id  # 문장이 끝나는 지점을 정의\n","        )\n","\n","    # 생성된 토큰을 텍스트로 디코딩\n","    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return generated_text\n","\n","# 병합된 프롬프트로 문장 생성\n","generated_output = generate_text(full_prompt)\n","\n","# 생성된 텍스트 출력\n","print(\"생성된 텍스트:\", generated_output)\n"]},{"cell_type":"code","source":["import os\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","model_id = 'MLP-KTLim/llama3-Bllossom'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    torch_dtype=torch.bfloat16,\n","    device_map=\"auto\",\n",")\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"Q2TYR659aZYO","executionInfo":{"status":"error","timestamp":1729051694934,"user_tz":-540,"elapsed":378,"user":{"displayName":"김상욱","userId":"12120376734160382512"}},"outputId":"0afb91df-75f4-4752-ec3f-4dde50086d74"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name '_C' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-37aa2b276847>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'MLP-KTLim/llama3-Bllossom'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0m__name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m__name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m__name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m__name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0m__all__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"]}]},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","import bitsandbytes as bnb  # 8비트 양자화를 위한 라이브러리\n","\n","# CUDA 사용 가능 여부 확인\n","if torch.cuda.is_available():\n","    print(\"CUDA is available. GPU를 사용할 수 있습니다.\")\n","else:\n","    print(\"CUDA is not available. CPU만 사용할 수 있습니다.\")\n","\n","# 모델과 토크나이저 로드\n","model_id = 'MLP-KTLim/llama3-Bllossom'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","\n","# 모델을 8비트 양자화하여 로드\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    load_in_8bit=True,             # 8비트 양자화 활성화\n","    device_map=\"auto\",             # GPU 자동 할당\n","    torch_dtype=torch.float16,     # Mixed Precision (bfloat16 -> float16)\n","    quantization_config=bnb.QuantizationConfig(bits=8)  # 8비트 양자화 설정\n",")\n","\n","# Gradient Checkpointing 활성화\n","model.gradient_checkpointing_enable()\n","\n","model.eval()  # 모델을 평가 모드로 설정\n","\n","# 키워드를 기반으로 하는 새로운 프롬프트와 지시사항\n","PROMPT = '''넌 굉장히 창의적인 모델이야'''\n","\n","# 사용자 요청에 따라 instruction을 구성\n","instruction = \"나의 핵심역량(원관념)은 전문성, 협응력, 주도성, 기획, 진행이고 각각에 맞는 비유문장과 설명을 작성해주세요.\"\n","\n","# 프롬프트 병합\n","full_prompt = f\"{PROMPT}\\n{instruction}\"\n","\n","def generate_text(prompt, max_length=1024, temperature=1.2, top_p=0.9):\n","    # 입력 프롬프트를 토크나이징\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n","\n","    # 모델을 통해 문장 생성\n","    with torch.no_grad():  # 평가 모드에서는 그래디언트 계산 비활성화\n","        outputs = model.generate(\n","            input_ids,\n","            max_length=max_length,   # 생성할 최대 문장의 길이\n","            do_sample=True,          # 샘플링 방식 사용\n","            temperature=temperature, # 생성의 무작위성 조절\n","            top_p=top_p,             # Top-p 샘플링을 통해 확률 상위 토큰들 중 선택\n","            repetition_penalty=1.1,  # 반복 방지\n","            eos_token_id=tokenizer.eos_token_id  # 문장이 끝나는 지점을 정의\n","        )\n","\n","    # 생성된 토큰을 텍스트로 디코딩\n","    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return generated_text\n","\n","# 병합된 프롬프트로 문장 생성\n","generated_output = generate_text(full_prompt)\n","\n","# 생성된 텍스트 출력\n","print(\"생성된 텍스트:\", generated_output)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"neJ7qmlAU-R6","executionInfo":{"status":"error","timestamp":1729051686788,"user_tz":-540,"elapsed":399,"user":{"displayName":"김상욱","userId":"12120376734160382512"}},"outputId":"30a79ae8-efa5-49be-e1cc-8c6118aa6e6f"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name '_C' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-1568ec708f8d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitsandbytes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbnb\u001b[0m  \u001b[0;31m# 8비트 양자화를 위한 라이브러리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# CUDA 사용 가능 여부 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0m__name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m__name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m__name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m__name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0m__all__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Jnqi2gmmU-PX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OgFhfRGCU-Hk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q48YjmG6pfTG"},"source":["## 04. 챗봇 인터페이스"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":688},"executionInfo":{"elapsed":6347,"status":"ok","timestamp":1728959128839,"user":{"displayName":"김상욱","userId":"12120376734160382512"},"user_tz":-540},"id":"meGQ7F1bsZpy","outputId":"22601076-4530-4e2c-9a89-f0abdae7803d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:222: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://914511682ae648c60a.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["<div><iframe src=\"https://914511682ae648c60a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":[]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import gradio as gr\n","\n","# PROMPT = '''당신은 20대 초반의 여성이고 이름은 '빵순이'입니다. 귀여운 말투로 메신저로 대화하듯이 간결하고 정확하게 대답해야 합니다.'''\n","PROMPT = '''당신은 유용한 AI 어시스턴트입니다. 사용자의 질의에 대해 친절하고 정확하게 답변해야 합니다.'''\n","\n","def generate_response(input_text, chat_history):\n","    messages = [{\"role\": \"system\", \"content\": f\"{PROMPT}\"}]\n","\n","    for message in chat_history:\n","        messages.append({\"role\": \"user\", \"content\": message[0]})\n","        messages.append({\"role\": \"assistant\", \"content\": message[1]})\n","\n","    messages.append({\"role\": \"user\", \"content\": input_text})\n","\n","    input_ids = tokenizer.apply_chat_template(\n","        messages, add_generation_prompt=True, return_tensors=\"pt\"\n","    ).to(model.device)\n","\n","    terminators = [\n","        tokenizer.eos_token_id,\n","        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n","    ]\n","\n","    outputs = model.generate(\n","        input_ids,\n","        max_new_tokens=256,\n","        eos_token_id=terminators,\n","        do_sample=True,\n","        temperature=0.6,\n","        top_p=0.9,\n","        repetition_penalty=1.1\n","    )\n","\n","    response = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)\n","\n","    chat_history.append((input_text, response))\n","\n","    return \"\", chat_history\n","\n","with gr.Blocks() as demo:\n","    chatbot = gr.Chatbot(height=600)\n","    msg = gr.Textbox()\n","    clear = gr.Button(\"Clear\")\n","\n","    msg.submit(generate_response, [msg, chatbot], [msg, chatbot])\n","    clear.click(lambda: None, None, chatbot, queue=False)\n","\n","demo.launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XbT1xb6OvRA-"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1zxXvmP7_mpFUv4147X4tRK0Oe2HcryoI","timestamp":1728955566833},{"file_id":"1fBOzUVZ6NRKk_ugeoTbAOokWKqSN47IG","timestamp":1714390693105}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"026cbcf406da4968a498f6436d8bb775":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad24d5e8318b4bf6956caa6096718f31","placeholder":"​","style":"IPY_MODEL_f6b9c672f38a4e0eaabeffced7d70d38","value":" 4/4 [00:00&lt;00:00,  5.58it/s]"}},"33fe287fcfa84176b79a5dd02775b4b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a352b7ca9beb45df8d097b4d8bc1f860","IPY_MODEL_63d6048a5e1146629652ac4c23e756de","IPY_MODEL_026cbcf406da4968a498f6436d8bb775"],"layout":"IPY_MODEL_9e059d832199453887afcc31d6208035"}},"443c6506c81d461883f7f45adec345fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63d6048a5e1146629652ac4c23e756de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_745f8282d19c407b8360a0099ba32710","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb70f9ff2d9a4aa9860717a270b61f0b","value":4}},"745f8282d19c407b8360a0099ba32710":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f00bc23f42345cea2c2cef54c942caa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e059d832199453887afcc31d6208035":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a352b7ca9beb45df8d097b4d8bc1f860":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f00bc23f42345cea2c2cef54c942caa","placeholder":"​","style":"IPY_MODEL_443c6506c81d461883f7f45adec345fc","value":"Loading checkpoint shards: 100%"}},"ad24d5e8318b4bf6956caa6096718f31":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6b9c672f38a4e0eaabeffced7d70d38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb70f9ff2d9a4aa9860717a270b61f0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"31e5a2377d5543a0a449448c5c4f3387":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a92f1baeca964a409d277a05e721de1b","IPY_MODEL_0fa2e51f6213420d94369c8cf6714fd6","IPY_MODEL_16f777e36242490ab15b057c1f8abd70"],"layout":"IPY_MODEL_d67238c3ccf443048a42ebcc704c45a1"}},"a92f1baeca964a409d277a05e721de1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dafe270c2864aac8d4245cca0cdf74b","placeholder":"​","style":"IPY_MODEL_cf182a21bb364ee6b0e822dc10d81ee3","value":"Loading checkpoint shards: 100%"}},"0fa2e51f6213420d94369c8cf6714fd6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_afa9852527ff426fa3599bb6f1f376f1","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_534911b654924a2bbd388935b535c12b","value":4}},"16f777e36242490ab15b057c1f8abd70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2716bc4e29c649388c943e00d124234e","placeholder":"​","style":"IPY_MODEL_cea1cecf03564c2abe581e019c01129e","value":" 4/4 [00:01&lt;00:00,  3.90it/s]"}},"d67238c3ccf443048a42ebcc704c45a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dafe270c2864aac8d4245cca0cdf74b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf182a21bb364ee6b0e822dc10d81ee3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afa9852527ff426fa3599bb6f1f376f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"534911b654924a2bbd388935b535c12b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2716bc4e29c649388c943e00d124234e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cea1cecf03564c2abe581e019c01129e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c2e5e94388846c0a5dcc1266f6a485c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53b3b413013d4e91b67356eb97649e85","IPY_MODEL_a8226eb399424e6787e93f8dc7b8e255","IPY_MODEL_a3d6f5e6f19647e59e5258dc99b51d98"],"layout":"IPY_MODEL_8063d16d70b447a5bce20c647b11f744"}},"53b3b413013d4e91b67356eb97649e85":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1320bbf4642b44f6b4c834ba23efc4df","placeholder":"​","style":"IPY_MODEL_443e2640b60b4f88be2377faa50e2a70","value":"Loading checkpoint shards: 100%"}},"a8226eb399424e6787e93f8dc7b8e255":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3536af6225e3456c9965d4abebcc6dd4","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a8a132a63b1459fac1478a9a2e901de","value":4}},"a3d6f5e6f19647e59e5258dc99b51d98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d909668954344ba0a6bb6ed12a66304a","placeholder":"​","style":"IPY_MODEL_e9e317bde20f48a7982aa92ecedc588a","value":" 4/4 [00:01&lt;00:00,  2.85it/s]"}},"8063d16d70b447a5bce20c647b11f744":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1320bbf4642b44f6b4c834ba23efc4df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"443e2640b60b4f88be2377faa50e2a70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3536af6225e3456c9965d4abebcc6dd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a8a132a63b1459fac1478a9a2e901de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d909668954344ba0a6bb6ed12a66304a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9e317bde20f48a7982aa92ecedc588a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4553489c08bd4c5987a163b4d8349cb2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_41ccc332cc40440db10135d2da17239e","IPY_MODEL_aa17805ee5894c6a91147642176c557a","IPY_MODEL_895ab69958904d27875a09011fe516f9"],"layout":"IPY_MODEL_55d6e42946fe461bbcbfb0e129a44c88"}},"41ccc332cc40440db10135d2da17239e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_244687fac58f4c34916918c711965bea","placeholder":"​","style":"IPY_MODEL_64e41bc660c3402b946015c3f7d0b912","value":"Loading checkpoint shards: 100%"}},"aa17805ee5894c6a91147642176c557a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17ce0c0cc03a4959ae6a7df78e4918b0","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dae0c51ba2da4824bf35d5580155e6c1","value":4}},"895ab69958904d27875a09011fe516f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19118d56739948049bc5ef930888eea2","placeholder":"​","style":"IPY_MODEL_1c72156d8d3545dd99a4ca648ac6b557","value":" 4/4 [00:01&lt;00:00,  4.02it/s]"}},"55d6e42946fe461bbcbfb0e129a44c88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"244687fac58f4c34916918c711965bea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64e41bc660c3402b946015c3f7d0b912":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17ce0c0cc03a4959ae6a7df78e4918b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dae0c51ba2da4824bf35d5580155e6c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19118d56739948049bc5ef930888eea2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c72156d8d3545dd99a4ca648ac6b557":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}